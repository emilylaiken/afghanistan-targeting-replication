{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da99dfcd",
   "metadata": {},
   "source": [
    "# Notebook 2: Machine Learning Models\n",
    "Includes replication code for:\n",
    "- Table S2\n",
    "- Table S3\n",
    "- Table S4\n",
    "- Table S6\n",
    "- Table S7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f985241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, KFold, StratifiedKFold, GridSearchCV, cross_val_predict\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import clone\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ea2f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleaxis(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddefa01",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "053acd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/interim_analysis_datasets/merged_household.csv')\n",
    "x = df[df.columns[28:]].copy()\n",
    "xcolumns = x.columns\n",
    "ids = df['hhid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0d5131",
   "metadata": {},
   "source": [
    "### Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0565112",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropMissing(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self, cols_to_check, colnames, threshold=None, variance_threshold=None):\n",
    "        self.cols_to_check = cols_to_check\n",
    "        self.colnames = colnames\n",
    "        self.threshold = threshold\n",
    "        self.variance_threshold = variance_threshold\n",
    "        self.columns_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = pd.DataFrame(X, columns=self.colnames)\n",
    "        self.columns_ = X.columns\n",
    "        missing = X[self.cols_to_check].isna().mean()\n",
    "        self.missing_frac = missing\n",
    "        var = X[self.cols_to_check].var()\n",
    "        self.variance = var\n",
    "        self.cols_to_drop = missing[(missing > self.threshold) | (var < self.variance_threshold)].index\n",
    "        self.cols_to_keep = missing[(missing <= self.threshold) & (var >= self.variance_threshold)].index\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = pd.DataFrame(X, columns=self.colnames)\n",
    "        return X.drop(self.cols_to_drop.values, axis=1)\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return list(set(self.columns_) - set(self.cols_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce3ff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Winsorizer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, limits=None):\n",
    "        self.limits = limits\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = pd.DataFrame(X)\n",
    "        if self.limits is None:\n",
    "            self.limits = (0.01, 0.99)\n",
    "        elif isinstance(self.limits, float):\n",
    "            self.limits = (self.limits, 1 - self.limits)\n",
    "\n",
    "        columns = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
    "        threshold_dict = {}\n",
    "\n",
    "        for column in columns:\n",
    "            low, high = X[column].quantile(self.limits)\n",
    "            threshold_dict[column] = (low, high)\n",
    "\n",
    "        self.columns_ = columns\n",
    "        self.threshold_dict_ = threshold_dict\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = pd.DataFrame(X)\n",
    "        X_t = X.copy()\n",
    "        def trim(x, low, high):\n",
    "            if pd.isna(x):\n",
    "                return x\n",
    "            else:\n",
    "                x = low if x < low else x\n",
    "                x = high if x > high else x\n",
    "                return x\n",
    "        trim_vec = np.vectorize(trim)\n",
    "\n",
    "        for column, tup in self.threshold_dict_.items():\n",
    "            X_t[column] = trim_vec(X_t[column], *tup)\n",
    "\n",
    "        return X_t\n",
    "\n",
    "    def get_feature_names(self, feature_in=None):\n",
    "        return self.columns_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcc66dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: To make thing run faster, I've used reduced hyperparameter grids for this replication code (since the\n",
    "# synthetic data is uncorrelated with the target, hyperparameter searches won't improve performance anyway). \n",
    "# The full hyperparameter grids used in the paper are commented out. Running with the full hyperparameter grids\n",
    "# on the synthetic data takes several hours on a server with 56 CPUs.\n",
    "\n",
    "#logistic_grid = {'winsorizer__limits':[(0., 1.), (0.005, .995)],\n",
    "#                 'dropmissing__threshold':[.5, .8, 1],\n",
    "#                 'dropmissing__variance_threshold':[0, 0.01, 0.1]}\n",
    "\n",
    "logistic_grid = {'winsorizer__limits':[(0., 1.)],\n",
    "                 'dropmissing__threshold':[.5],\n",
    "                 'dropmissing__variance_threshold':[0]}\n",
    "\n",
    "logistic = Pipeline([('dropmissing', DropMissing(cols_to_check=xcolumns, colnames=xcolumns)),  \n",
    "                     ('winsorizer', Winsorizer()), \n",
    "                     ('imputer', SimpleImputer(strategy='mean')),\n",
    "                     ('scaler', MinMaxScaler()),\n",
    "                     ('model', SGDClassifier(loss='log', penalty='l1', alpha=0.000000000000001, n_jobs=1, \n",
    "                                             random_state=1))])\n",
    "\n",
    "#lasso_grid = {'winsorizer__limits':[(0., 1.), (0.005, .995)],\n",
    "#              'dropmissing__threshold':[.5, .8, 1],\n",
    "#              'dropmissing__variance_threshold':[0, 0.01, 0.1],\n",
    "#              'model__alpha':[.00001, .0001, .001, .01, .1, 1, 10, 100]}\n",
    "\n",
    "lasso_grid = {'winsorizer__limits':[(0., 1.)],\n",
    "              'dropmissing__threshold':[.5],\n",
    "              'dropmissing__variance_threshold':[0.1],\n",
    "              'model__alpha':[1]}\n",
    "\n",
    "lasso = Pipeline([('dropmissing', DropMissing(cols_to_check=xcolumns, colnames=xcolumns)),  \n",
    "                  ('winsorizer', Winsorizer()), \n",
    "                  ('imputer', SimpleImputer(strategy='mean')),\n",
    "                  ('scaler', MinMaxScaler()),\n",
    "                  ('model', SGDClassifier(loss='log', penalty='l1', n_jobs=1, random_state=1))])\n",
    "\n",
    "#rf_grid = {'winsorizer__limits':[(0., 1.), (0.005, .995)],\n",
    "#           'dropmissing__threshold':[.5, .8, 1],\n",
    "#           'dropmissing__variance_threshold':[0, 0.01, 0.1],\n",
    "#           'model__n_estimators':[50, 100, 200],\n",
    "#           'model__max_depth':[2, 4, 6, 8]}\n",
    "\n",
    "rf_grid = {'winsorizer__limits':[(0., 1.)],\n",
    "           'dropmissing__threshold':[.5],\n",
    "           'dropmissing__variance_threshold':[0],\n",
    "           'model__n_estimators':[50],\n",
    "           'model__max_depth':[2]}\n",
    "\n",
    "rf = Pipeline([('dropmissing', DropMissing(cols_to_check=xcolumns, colnames=xcolumns)),  \n",
    "               ('winsorizer', Winsorizer()), \n",
    "               ('imputer', SimpleImputer(strategy='mean')),\n",
    "               ('scaler', MinMaxScaler()),\n",
    "               ('model', RandomForestClassifier(n_jobs=-1, random_state=1, criterion='entropy'))])\n",
    "\n",
    "#lgbm_grid = {'winsorizer__limits':[(0., 1.), (0.005, .995)],\n",
    "#             'dropmissing__threshold':[.5, .8, 1],\n",
    "#             'dropmissing__variance_threshold':[0, 0.01, 0.1],\n",
    "#             'model__n_estimators':[50, 100, 200],\n",
    "#             'model__min_data_in_leaf':[20, 50, 100], \n",
    "#             'model__num_leaves':[5, 10],\n",
    "#             'model__learning_rate':[0.05, 0.075]}\n",
    "\n",
    "lgbm_grid = {'winsorizer__limits':[(0., 1.)],\n",
    "             'dropmissing__threshold':[.5],\n",
    "             'dropmissing__variance_threshold':[0],\n",
    "             'model__n_estimators':[50],\n",
    "             'model__min_data_in_leaf':[20], \n",
    "             'model__num_leaves':[5],\n",
    "             'model__learning_rate':[0.05]}\n",
    "\n",
    "lgbm = Pipeline([('dropmissing', DropMissing(cols_to_check=xcolumns, colnames=xcolumns)), \n",
    "                ('winsorizer', Winsorizer()), \n",
    "                ('model', LGBMClassifier(n_jobs=1, random_state=1))])\n",
    "    \n",
    "regression_models = {\n",
    "    'logistic':SGDRegressor(loss='squared_loss', penalty='l1', alpha=0.000000000000001, random_state=1),\n",
    "    'lasso':SGDRegressor(loss='squared_loss', penalty='l1', random_state=1),\n",
    "    'rf':RandomForestRegressor(n_jobs=-1, random_state=1),\n",
    "    'lgbm':LGBMRegressor(n_jobs=-1, random_state=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad943c9b",
   "metadata": {},
   "source": [
    "### Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4150cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ultra_poor, logistic...\n",
      "logistic Score: 0.4910\n",
      "Running ultra_poor, lasso...\n",
      "lasso Score: 0.4988\n",
      "Running ultra_poor, rf...\n",
      "rf Score: 0.5120\n",
      "Running ultra_poor, lgbm...\n",
      "lgbm Score: 0.5000\n",
      "Running asset_index, logistic...\n",
      "logistic Score: -0.1655\n",
      "Running asset_index, lasso...\n",
      "lasso Score: -0.0072\n",
      "Running asset_index, rf...\n",
      "rf Score: -0.0099\n",
      "Running asset_index, lgbm...\n",
      "lgbm Score: -0.0074\n",
      "Running log_expend, logistic...\n",
      "logistic Score: 0.5664\n",
      "Running log_expend, lasso...\n",
      "lasso Score: -0.0018\n",
      "Running log_expend, rf...\n",
      "rf Score: 0.6446\n",
      "Running log_expend, lgbm...\n",
      "lgbm Score: 0.6490\n",
      "Running below_poverty_line, logistic...\n",
      "logistic Score: 0.9944\n",
      "Running below_poverty_line, lasso...\n",
      "lasso Score: 0.4952\n",
      "Running below_poverty_line, rf...\n",
      "rf Score: 0.9814\n",
      "Running below_poverty_line, lgbm...\n",
      "lgbm Score: 1.0000\n",
      "Running cwr_group, logistic...\n",
      "logistic Score: -0.3058\n",
      "Running cwr_group, lasso...\n",
      "lasso Score: -0.0026\n",
      "Running cwr_group, rf...\n",
      "rf Score: -0.0241\n",
      "Running cwr_group, lgbm...\n",
      "lgbm Score: -0.0881\n"
     ]
    }
   ],
   "source": [
    "for outcome, method in [('ultra_poor', 'classification'), ('asset_index', 'regression'), \n",
    "                        ('log_expend', 'regression'), ('below_poverty_line', 'classification'), \n",
    "                        ('cwr_group', 'regression')]:\n",
    "    for base_model, grid, label in [(logistic, logistic_grid, 'logistic'), (lasso, lasso_grid, 'lasso'), \n",
    "                                     (rf, rf_grid, 'rf'), (lgbm, lgbm_grid, 'lgbm')]:\n",
    "\n",
    "        # Define y variable\n",
    "        y = df[outcome]\n",
    "\n",
    "        # Get file names\n",
    "        print('Running ' + outcome + ', ' + label + '...')\n",
    "        base_folder = 'results/simulations/' + outcome + '/' + label + '/'\n",
    "        if not os.path.isdir(base_folder[:-1]):\n",
    "            os.mkdir(base_folder[:-1])\n",
    "\n",
    "        # Use classification if a classification outcome, else use regression\n",
    "        base_model = clone(base_model)\n",
    "        if method == 'classification':\n",
    "            inner_strat = StratifiedKFold(n_splits=3, shuffle=True, random_state=15)\n",
    "            outer_strat = StratifiedKFold(n_splits=10, shuffle=True, random_state=14) \n",
    "            scoring = 'roc_auc'\n",
    "            scoring_method = 'predict_proba'\n",
    "        else:\n",
    "            base_model.set_params(model=regression_models[label])\n",
    "            inner_strat = KFold(n_splits=3, shuffle=True, random_state=15)\n",
    "            outer_strat = KFold(n_splits=10, shuffle=True, random_state=14)\n",
    "            scoring = 'r2'\n",
    "            scoring_method = 'predict'\n",
    "\n",
    "        # Create grid search object\n",
    "        model = GridSearchCV(estimator=base_model, param_grid=grid, cv=inner_strat, scoring=scoring, \n",
    "                             verbose=10, refit=True)\n",
    "\n",
    "        # Get predictions out of sample over 10-fold CV and save to file\n",
    "        yhat = cross_val_predict(model, x, y, method=scoring_method, n_jobs=-1, cv=outer_strat)\n",
    "        if method == 'classification':\n",
    "            yhat = yhat[:, 1]\n",
    "        predictions_df = pd.DataFrame([ids, y, yhat]).T\n",
    "        predictions_df.columns = ['hhid', 'y', 'yhat']\n",
    "        predictions_df.to_csv(base_folder + 'predictions.csv', index=False)\n",
    "        if method == 'classification':\n",
    "            print((label + ' Score: %.4f') % roc_auc_score(y, yhat))\n",
    "        else:\n",
    "            print((label + ' Score: %.4f') % r2_score(y, yhat))\n",
    "\n",
    "        # Retrain model on all data to save information on hyperparameters and feature importances\n",
    "        model.n_jobs = -1\n",
    "        model.verbose = 0\n",
    "        model.fit(x, y)\n",
    "        \n",
    "        # Save the model itself\n",
    "        dump(model, base_folder + 'model')\n",
    "        \n",
    "        # Save the dataframe of tuning results\n",
    "        resultsdf = pd.DataFrame(model.cv_results_)\n",
    "        resultsdf.to_csv(base_folder + 'tuning.csv', index=False)\n",
    "        \n",
    "        # Save the dataframe of feature importances\n",
    "        try:\n",
    "            imports = model.best_estimator_.named_steps['model'].feature_importances_\n",
    "        except:\n",
    "            imports = model.best_estimator_.named_steps['model'].coef_\n",
    "        cols_kept = model.best_estimator_.named_steps['dropmissing'].cols_to_keep\n",
    "        imports = pd.DataFrame([cols_kept, imports]).T\n",
    "        imports.columns = ['feature', 'importance']\n",
    "        imports.to_csv(base_folder + 'feature_importances.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314c11a6",
   "metadata": {},
   "source": [
    "### Machine learning from phone data with individual-level matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb7f0a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/interim_analysis_datasets/merged_individual.csv')\n",
    "x = df[df.columns[28:]].copy()\n",
    "xcolumns = x.columns\n",
    "ids = df['hhid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99e42b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ultra_poor, logistic...\n",
      "logistic Score: 0.4856\n",
      "Running ultra_poor, lasso...\n",
      "lasso Score: 0.5038\n",
      "Running ultra_poor, rf...\n",
      "rf Score: 0.5388\n",
      "Running ultra_poor, lgbm...\n",
      "lgbm Score: 0.5228\n"
     ]
    }
   ],
   "source": [
    "outcome, method = 'ultra_poor', 'classification'\n",
    "for base_model, grid, label in [(logistic, logistic_grid, 'logistic'), (lasso, lasso_grid, 'lasso'), \n",
    "                                 (rf, rf_grid, 'rf'), (lgbm, lgbm_grid, 'lgbm')]:\n",
    "\n",
    "    # Define y variable\n",
    "    y = df[outcome]\n",
    "\n",
    "    # Get file names\n",
    "    print('Running ' + outcome + ', ' + label + '...')\n",
    "    base_folder = 'results/simulations/' + outcome + '/individual/' + label + '/'\n",
    "    if not os.path.isdir(base_folder[:-1]):\n",
    "        os.mkdir(base_folder[:-1])\n",
    "\n",
    "    # Use classification if a classification outcome, else use regression\n",
    "    base_model = clone(base_model)\n",
    "    if method == 'classification':\n",
    "        inner_strat = StratifiedKFold(n_splits=3, shuffle=True, random_state=15)\n",
    "        outer_strat = StratifiedKFold(n_splits=10, shuffle=True, random_state=14) \n",
    "        scoring = 'roc_auc'\n",
    "        scoring_method = 'predict_proba'\n",
    "    else:\n",
    "        base_model.set_params(model=regression_models[label])\n",
    "        inner_strat = KFold(n_splits=3, shuffle=True, random_state=15)\n",
    "        outer_strat = KFold(n_splits=10, shuffle=True, random_state=14)\n",
    "        scoring = 'r2'\n",
    "        scoring_method = 'predict'\n",
    "\n",
    "    # Create grid search object\n",
    "    model = GridSearchCV(estimator=base_model, param_grid=grid, cv=inner_strat, scoring=scoring, \n",
    "                         verbose=10, refit=True)\n",
    "\n",
    "    # Get predictions out of sample over 10-fold CV and save to file\n",
    "    yhat = cross_val_predict(model, x, y, method=scoring_method, n_jobs=-1, cv=outer_strat)\n",
    "    if method == 'classification':\n",
    "        yhat = yhat[:, 1]\n",
    "    predictions_df = pd.DataFrame([ids, y, yhat]).T\n",
    "    predictions_df.columns = ['hhid', 'y', 'yhat']\n",
    "    predictions_df.to_csv(base_folder + 'predictions.csv', index=False)\n",
    "    if method == 'classification':\n",
    "        print((label + ' Score: %.4f') % roc_auc_score(y, yhat))\n",
    "    else:\n",
    "        print((label + ' Score: %.4f') % r2_score(y, yhat))\n",
    "\n",
    "    # Retrain model on all data to save information on hyperparameters and feature importances\n",
    "    model.n_jobs = -1\n",
    "    model.verbose = 0\n",
    "    model.fit(x, y)\n",
    "\n",
    "    # Save the model itself\n",
    "    dump(model, base_folder + 'model')\n",
    "\n",
    "    # Save the dataframe of tuning results\n",
    "    resultsdf = pd.DataFrame(model.cv_results_)\n",
    "    resultsdf.to_csv(base_folder + 'tuning.csv', index=False)\n",
    "\n",
    "    # Save the dataframe of feature importances\n",
    "    try:\n",
    "        imports = model.best_estimator_.named_steps['model'].feature_importances_\n",
    "    except:\n",
    "        imports = model.best_estimator_.named_steps['model'].coef_\n",
    "    cols_kept = model.best_estimator_.named_steps['dropmissing'].cols_to_keep\n",
    "    imports = pd.DataFrame([cols_kept, imports]).T\n",
    "    imports.columns = ['feature', 'importance']\n",
    "    imports.to_csv(base_folder + 'feature_importances.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b2debe",
   "metadata": {},
   "source": [
    "### Machine learning with asset data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b655d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/interim_analysis_datasets/merged_household.csv')\n",
    "x = df[[col for col in df.columns if 'asset' in col and col != 'asset_index']].astype('float')\n",
    "xcolumns = x.columns\n",
    "ids = df['hhid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3841360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic_grid = {'winsorizer__limits':[(0., 1.), (0.005, .995)],\n",
    "#                 'dropmissing__threshold':[.5, .8, 1],\n",
    "#                 'dropmissing__variance_threshold':[0, 0.01, 0.1]}\n",
    "\n",
    "logistic_grid = {'winsorizer__limits':[(0., 1.)],\n",
    "                 'dropmissing__threshold':[.5],\n",
    "                 'dropmissing__variance_threshold':[0]}\n",
    "\n",
    "logistic = Pipeline([('dropmissing', DropMissing(cols_to_check=xcolumns, colnames=xcolumns)),  \n",
    "                     ('winsorizer', Winsorizer()), \n",
    "                     ('imputer', SimpleImputer(strategy='mean')),\n",
    "                     ('scaler', MinMaxScaler()),\n",
    "                     ('model', SGDClassifier(loss='log', penalty='l1', alpha=0.000000000000001, n_jobs=1, \n",
    "                                             random_state=1))])\n",
    "\n",
    "#lasso_grid = {'winsorizer__limits':[(0., 1.), (0.005, .995)],\n",
    "#              'dropmissing__threshold':[.5, .8, 1],\n",
    "#              'dropmissing__variance_threshold':[0, 0.01, 0.1],\n",
    "#              'model__alpha':[.00001, .0001, .001, .01, .1, 1, 10, 100]}\n",
    "\n",
    "lasso_grid = {'winsorizer__limits':[(0., 1.)],\n",
    "              'dropmissing__threshold':[.5],\n",
    "              'dropmissing__variance_threshold':[0.1],\n",
    "              'model__alpha':[1]}\n",
    "\n",
    "lasso = Pipeline([('dropmissing', DropMissing(cols_to_check=xcolumns, colnames=xcolumns)),  \n",
    "                  ('winsorizer', Winsorizer()), \n",
    "                  ('imputer', SimpleImputer(strategy='mean')),\n",
    "                  ('scaler', MinMaxScaler()),\n",
    "                  ('model', SGDClassifier(loss='log', penalty='l1', n_jobs=1, random_state=1))])\n",
    "\n",
    "#rf_grid = {'winsorizer__limits':[(0., 1.), (0.005, .995)],\n",
    "#           'dropmissing__threshold':[.5, .8, 1],\n",
    "#           'dropmissing__variance_threshold':[0, 0.01, 0.1],\n",
    "#           'model__n_estimators':[50, 100, 200],\n",
    "#           'model__max_depth':[2, 4, 6, 8]}\n",
    "\n",
    "rf_grid = {'winsorizer__limits':[(0., 1.)],\n",
    "           'dropmissing__threshold':[.5],\n",
    "           'dropmissing__variance_threshold':[0],\n",
    "           'model__n_estimators':[50],\n",
    "           'model__max_depth':[2]}\n",
    "\n",
    "rf = Pipeline([('dropmissing', DropMissing(cols_to_check=xcolumns, colnames=xcolumns)),  \n",
    "               ('winsorizer', Winsorizer()), \n",
    "               ('imputer', SimpleImputer(strategy='mean')),\n",
    "               ('scaler', MinMaxScaler()),\n",
    "               ('model', RandomForestClassifier(n_jobs=-1, random_state=1, criterion='entropy'))])\n",
    "\n",
    "#lgbm_grid = {'winsorizer__limits':[(0., 1.), (0.005, .995)],\n",
    "#             'dropmissing__threshold':[.5, .8, 1],\n",
    "#             'dropmissing__variance_threshold':[0, 0.01, 0.1],\n",
    "#             'model__n_estimators':[50, 100, 200],\n",
    "#             'model__min_data_in_leaf':[20, 50, 100], \n",
    "#             'model__num_leaves':[5, 10],\n",
    "#             'model__learning_rate':[0.05, 0.075]}\n",
    "\n",
    "lgbm_grid = {'winsorizer__limits':[(0., 1.)],\n",
    "             'dropmissing__threshold':[.5],\n",
    "             'dropmissing__variance_threshold':[0],\n",
    "             'model__n_estimators':[50],\n",
    "             'model__min_data_in_leaf':[20], \n",
    "             'model__num_leaves':[5],\n",
    "             'model__learning_rate':[0.05]}\n",
    "\n",
    "lgbm = Pipeline([('dropmissing', DropMissing(cols_to_check=xcolumns, colnames=xcolumns)), \n",
    "                ('winsorizer', Winsorizer()), \n",
    "                ('model', LGBMClassifier(n_jobs=1, random_state=1))])\n",
    "    \n",
    "regression_models = {\n",
    "    'logistic':SGDRegressor(loss='squared_loss', penalty='l1', alpha=0.000000000000001, random_state=1),\n",
    "    'lasso':SGDRegressor(loss='squared_loss', penalty='l1', random_state=1),\n",
    "    'rf':RandomForestRegressor(n_jobs=-1, random_state=1),\n",
    "    'lgbm':LGBMRegressor(n_jobs=-1, random_state=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "292045cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ultra_poor, logistic...\n",
      "logistic Score: 0.5045\n",
      "Running ultra_poor, lasso...\n",
      "lasso Score: 0.4988\n",
      "Running ultra_poor, rf...\n",
      "rf Score: 0.4775\n",
      "Running ultra_poor, lgbm...\n",
      "lgbm Score: 0.5297\n"
     ]
    }
   ],
   "source": [
    "outcome, method = 'ultra_poor', 'classification'\n",
    "for base_model, grid, label in [(logistic, logistic_grid, 'logistic'), (lasso, lasso_grid, 'lasso'), \n",
    "                                 (rf, rf_grid, 'rf'), (lgbm, lgbm_grid, 'lgbm')]:\n",
    "\n",
    "    # Define y variable\n",
    "    y = df[outcome].astype('float')\n",
    "\n",
    "    # Get file names\n",
    "    print('Running ' + outcome + ', ' + label + '...')\n",
    "    base_folder = 'results/simulations/' + outcome + '/asset_data/' + label + '/'\n",
    "    if not os.path.isdir(base_folder[:-1]):\n",
    "        os.mkdir(base_folder[:-1])\n",
    "\n",
    "    # Use classification if a classification outcome, else use regression\n",
    "    base_model = clone(base_model)\n",
    "    if method == 'classification':\n",
    "        inner_strat = StratifiedKFold(n_splits=3, shuffle=True, random_state=15)\n",
    "        outer_strat = StratifiedKFold(n_splits=10, shuffle=True, random_state=14) \n",
    "        scoring = 'roc_auc'\n",
    "        scoring_method = 'predict_proba'\n",
    "    else:\n",
    "        base_model.set_params(model=regression_models[label])\n",
    "        inner_strat = KFold(n_splits=3, shuffle=True, random_state=15)\n",
    "        outer_strat = KFold(n_splits=10, shuffle=True, random_state=14)\n",
    "        scoring = 'r2'\n",
    "        scoring_method = 'predict'\n",
    "\n",
    "    # Create grid search object\n",
    "    model = GridSearchCV(estimator=base_model, param_grid=grid, cv=inner_strat, scoring=scoring, \n",
    "                         verbose=10, refit=True)\n",
    "\n",
    "    # Get predictions out of sample over 10-fold CV and save to file\n",
    "    yhat = cross_val_predict(model, x, y, method=scoring_method, n_jobs=-1, cv=outer_strat)\n",
    "    if method == 'classification':\n",
    "        yhat = yhat[:, 1]\n",
    "    predictions_df = pd.DataFrame([ids, y, yhat]).T\n",
    "    predictions_df.columns = ['hhid', 'y', 'yhat']\n",
    "    predictions_df.to_csv(base_folder + 'predictions.csv', index=False)\n",
    "    if method == 'classification':\n",
    "        print((label + ' Score: %.4f') % roc_auc_score(y, yhat))\n",
    "    else:\n",
    "        print((label + ' Score: %.4f') % r2_score(y, yhat))\n",
    "\n",
    "    # Retrain model on all data to save information on hyperparameters and feature importances\n",
    "    model.n_jobs = -1\n",
    "    model.verbose = 0\n",
    "    model.fit(x, y)\n",
    "\n",
    "    # Save the model itself\n",
    "    dump(model, base_folder + 'model')\n",
    "\n",
    "    # Save the dataframe of tuning results\n",
    "    resultsdf = pd.DataFrame(model.cv_results_)\n",
    "    resultsdf.to_csv(base_folder + 'tuning.csv', index=False)\n",
    "\n",
    "    # Save the dataframe of feature importances\n",
    "    try:\n",
    "        imports = model.best_estimator_.named_steps['model'].feature_importances_\n",
    "    except:\n",
    "        imports = model.best_estimator_.named_steps['model'].coef_\n",
    "    cols_kept = model.best_estimator_.named_steps['dropmissing'].cols_to_keep\n",
    "    imports = pd.DataFrame([cols_kept, imports]).T\n",
    "    imports.columns = ['feature', 'importance']\n",
    "    imports.to_csv(base_folder + 'feature_importances.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e618357a",
   "metadata": {},
   "source": [
    "### Table S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb9fa4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_feature(x):\n",
    "    if x[:19] == 'balance of contacts':\n",
    "        x = 'BOC' + x[19:]\n",
    "    elif x[:21] == 'number of interaction':\n",
    "        x = 'NOI' + x[21:]\n",
    "    elif x[:24] == 'interactions per contact':\n",
    "        x = 'IPC' + x[24:]\n",
    "    elif x[:27] == 'percent pareto interactions':\n",
    "        x = 'PPI' + x[27:]\n",
    "    elif x[:24] == 'percent pareto durations':\n",
    "        x = 'PPD' + x[24:]\n",
    "    elif x[:15] == 'interevent time':\n",
    "        x = 'IT' + x[15:]\n",
    "    elif x[:13] == 'call duration':\n",
    "        x = 'CD' + x[13:]\n",
    "    elif x[:14] == 'response delay':\n",
    "        x = 'RD' + x[14:]\n",
    "    elif x[:13] == 'response rate':\n",
    "        x = 'RR' + x[13:]\n",
    "    tokenized = x.split(' ')\n",
    "    for i in range(len(tokenized)):\n",
    "        if tokenized[i] == 'average':\n",
    "            tokenized[i] = 'avg'\n",
    "        elif tokenized[i] == 'weekend':\n",
    "            tokenized[i] = 'WE'\n",
    "        elif tokenized[i] == 'weekday':\n",
    "            tokenized[i] = 'WD'\n",
    "        elif tokenized[i] == 'allweek':\n",
    "            tokenized[i] = ''\n",
    "        elif tokenized[i] == 'allday':\n",
    "            tokenized[i] = ''\n",
    "        elif tokenized[i] == 'skewness':\n",
    "            tokenized[i] = 'skew'\n",
    "        elif tokenized[i] == 'number':\n",
    "            tokenized[i] = '#'\n",
    "        elif tokenized[i] == 'percent':\n",
    "            tokenized[i] = '%'\n",
    "        elif tokenized[i] == 'of':\n",
    "            tokenized[i] = ''\n",
    "        elif tokenized[i] == 'callandtext':\n",
    "            tokenized[i] = ''\n",
    "        elif tokenized[i] == ' ':\n",
    "            tokenized[i] = ''\n",
    "        if tokenized[i] not in ['BOC', 'NOI', 'IPC', 'PPI', 'PPD', 'IT', 'CD', 'RD', 'RR', 'WE', 'WD']:\n",
    "            tokenized[i] = tokenized[i].capitalize()\n",
    "    return ' '.join(tokenized).replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5032d6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>CD WE Night Call Median</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CD Night Call Mean</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CD  Call Min</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>RR Text WD</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>BOC WD Night Call Std</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature  importance\n",
       "37   CD WE Night Call Median           9\n",
       "22        CD Night Call Mean           8\n",
       "16              CD  Call Min           8\n",
       "99                RR Text WD           7\n",
       "145    BOC WD Night Call Std           7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.read_csv('results/simulations/ultra_poor/lgbm/feature_importances.csv')\\\n",
    "    [['feature', 'importance']]\\\n",
    "    .dropna(subset=['importance'])\\\n",
    "    .sort_values('importance', ascending=False)\n",
    "importances['feature'] = importances['feature']\\\n",
    "    .apply(lambda x: ', '.join([format_feature(' '.join([s for s in str(x).split('_') if s != ''])).strip()]))\n",
    "importances[:50].to_csv('results/tables/tables2.csv', index=False)\n",
    "importances.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6503fd3",
   "metadata": {},
   "source": [
    "### Tables S3, S4, S6, and S7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34fb4c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>r2 or AUC</th>\n",
       "      <th>Top Five Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>Below Poverty Line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LASSO Regression</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>Below Poverty Line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>BOC WE Night Call Kurtosis, CD Night Call Mean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>CD WE Night Call Median, CD Night Call Mean, C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  r2 or AUC  \\\n",
       "0  Linear Regression      -0.81   \n",
       "1   LASSO Regression      -0.01   \n",
       "2      Random Forest      -0.01   \n",
       "3  Gradient Boosting      -0.01   \n",
       "\n",
       "                                   Top Five Features  \n",
       "0                                 Below Poverty Line  \n",
       "1                                 Below Poverty Line  \n",
       "2  BOC WE Night Call Kurtosis, CD Night Call Mean...  \n",
       "3  CD WE Night Call Median, CD Night Call Mean, C...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up labels\n",
    "models = ['logistic', 'lasso', 'rf', 'lgbm']\n",
    "classification_model_labels = ['Logistic (No Penalty)', 'Logistic (L1 Penalty)', 'Random Forest', \n",
    "                               'Gradient Boosting']\n",
    "regression_model_labels = ['Linear Regression', 'LASSO Regression', 'Random Forest', 'Gradient Boosting']\n",
    "\n",
    "for outcome, method in [('ultra_poor', 'classification'), ('asset_index', 'regression'), \n",
    "                        ('log_expend', 'regression'), ('below_poverty_line', 'regression'), \n",
    "                        ('cwr_group', 'regression'), ('ultra_poor/individual', 'classification'),\n",
    "                        ('ultra_poor/asset_data', 'regression')]:\n",
    "\n",
    "    # Set up table\n",
    "    table = []\n",
    "    for m, model in enumerate(models):\n",
    "\n",
    "        # Model score\n",
    "        predictions = pd.read_csv('results/simulations/' + outcome + '/' + model + '/predictions.csv')\n",
    "        if method == 'classification':\n",
    "            score = roc_auc_score(predictions['y'], predictions['yhat'])\n",
    "        else:\n",
    "            score = r2_score(predictions['y'], predictions['yhat'])\n",
    "        score = round(score, 2)\n",
    "\n",
    "        # Top features\n",
    "        importances = pd.read_csv('results/simulations/ultra_poor/' + model + '/feature_importances.csv')\\\n",
    "            [['feature', 'importance']]\\\n",
    "            .dropna(subset=['importance'])\\\n",
    "            .sort_values('importance', ascending=False)\\\n",
    "            .head(5)\n",
    "        importances['feature'] = importances['feature']\\\n",
    "            .apply(lambda x: ', '.join([format_feature(' '.join([s for s in str(x).split('_') if s != '']))\\\n",
    "                                        .strip()]))\n",
    "        importances = ', '.join(list(importances['feature']))\n",
    "\n",
    "        # Append row\n",
    "        if method == 'classification':\n",
    "            table.append([regression_model_labels[m], score, importances])\n",
    "        else:\n",
    "            table.append([regression_model_labels[m], score, importances])\n",
    "            \n",
    "    # Make table, write to file\n",
    "    table = pd.DataFrame(table)\n",
    "    table.columns = ['Model', 'r2 or AUC', 'Top Five Features']\n",
    "    if outcome == 'ultra_poor':\n",
    "        table.to_csv('results/tables/tables3.csv', index=False)\n",
    "    elif outcome == 'ultra_poor/asset_data':\n",
    "        table.to_csv('results/tables/tables4.csv', index=False)\n",
    "    elif outcome == 'ultra_poor/individual':\n",
    "        table.to_csv('results/tables/tables6.csv', index=False)\n",
    "    else:\n",
    "        table.to_csv('results/tables/tables7_panel' + outcome + '.csv', index=False)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d0df9",
   "metadata": {},
   "source": [
    "### Combining data sources with machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5111425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge survey data and CDR-based predictions\n",
    "df = pd.read_csv('data/interim_analysis_datasets/merged_household.csv')\\\n",
    "    [['hhid', 'ultra_poor', 'log_expend', 'asset_index', 'weight']]\n",
    "predictions = pd.read_csv('results/simulations/ultra_poor/lgbm/predictions.csv')[['hhid', 'yhat']]\\\n",
    "    .rename({'yhat':'cdr'}, axis=1)\n",
    "df = df.merge(predictions, on='hhid', how='inner')\n",
    "\n",
    "# Set up model, data, and cross validation\n",
    "y = df['ultra_poor']\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=13)\n",
    "model = LogisticRegression(penalty='none', n_jobs=1, random_state=100)\n",
    "\n",
    "# Try different combinations of data together\n",
    "for regressors in [['asset_index', 'log_expend'], ['asset_index', 'cdr'], ['log_expend', 'cdr'], \n",
    "                   ['asset_index', 'log_expend', 'cdr']]:\n",
    "    x = df[regressors]\n",
    "    scores = cross_validate(model, x, y, scoring='roc_auc', cv=cv)\n",
    "    predictions = cross_val_predict(model, x, y, method='predict_proba', cv=cv)\n",
    "    df['+'.join(regressors)] = predictions[:, 1]\n",
    "    \n",
    "# Write to file for later analysis\n",
    "df.to_csv('data/interim_analysis_datasets/merged_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4779c226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
